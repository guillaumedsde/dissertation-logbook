---
title: "UI Improvements"
date: 2019-11-12T15:56:28Z
draft: false
---

## Progress

Over the course of this week, I have managed to implement a couple of features:

- Proper component UI for list of document sets and documents
- delete documents delete documents sets
- document Set metadata (size and document count)
- loading animations for document and documents set list
- properly reload document and document set list when a change happens (new element or delete element)
- gradual highlighting opacity for document feature depending on their importance
- preserve formatting of text document (respect line returns, align text on right)
- improve speed of document classification and explanation
- independently toggle "positive" explanations and "negative" explanations

## Setbacks

As detailed in {{< ref "posts/shap-explainer.md" >}} I have not managed to implement a second explainer, the SHAP explainer.

I have spent some time trying to get the upload of an entire document set at once to work but have not managed to implement it. It could be that the OpenAPI code generator for the javascript client is buggy because `multipart/form-data` from the Javascript client does not put the correct form-data parameters, it could also well be that I am missing something in the [OpenAPI file upload documentation](https://swagger.io/docs/specification/describing-request-body/file-upload/) that is a bit light. I could try and implement my own document upload function, but before doing that I will try and find another codebase that uses a similar stack (namely OpenAPI and its autogenerated javscript API client).

## UI Demo

_(right click -> view image for bigger image)_

{{< figure src="/ui-improvements/doc_set_creation.gif" caption="Document Set and Document Creation" >}}

{{< figure src="/ui-improvements/document_edit.gif" caption="Document sensitivity visualisation toggle and early redaction menu" >}}

## What then?

I would like to get the SHAP explainer working to have at least two to be able to compare, the frontend "toggling" between the two is easy enough but I've been struggling with making it work in the backend.

Also trying to get the "multiple file upload" working would be nice. Once it is done it is easy to accept different file types and depending on the file type to render it or not (render the HTML but keep the plaintext intact). This would avoid having to code a "populator" program which would take the current files and would render the HTML before uploading it to elasticsearch. Since I'd program it anyway, might as well make it a feature.

A more complex goal would be classifying the documents on upload, this would allow for an insight into the entire document set collection, sorting it by document sensitivity and faster loading times. A problem then becomes, how to "reclassify" documents when the model changes? I've got some ideas, like storing a hash of the file of the stored model, but realistically I'm not yet at the stage where I modify the model in "real time" anyway, so that will be a worry for later.

Lastly, there are a couple of bugs here and there, notably the highlighting of sensitive features is just a regex of a text string on the main body without any notion of text "token", some strings which are subsets of other strings still get highlighted, I will explore this when I have time. Another idea that was brought up was the possibility to use multiple classifiers, which should not be too hard, but first I need to figure out document classification on upload beforehand.
